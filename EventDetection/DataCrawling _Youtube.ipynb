{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4 crawling data from Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.oauth2.credentials\n",
    "from apiclient.discovery import build\n",
    "from apiclient.errors import HttpError\n",
    "from oauth2client.tools import argparser\n",
    "import numpy as np\n",
    "import pymongo\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "import json\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "\"\"\"connect to monoDB\"\"\"\n",
    "\n",
    "client = MongoClient()\n",
    "\n",
    "db = client.youtube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.geo-based data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set DEVELOPER_KEY to the API key value from the APIs & auth > Registered apps\n",
    "# tab of\n",
    "#   https://cloud.google.com/console\n",
    "# Please ensure that you have enabled the YouTube Data API for your project.\n",
    "DEVELOPER_KEY = \"AIzaSyAS66bGuv6yYysm_Rh5im6iZ2jjeuPAbpg\"\n",
    "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
    "YOUTUBE_API_VERSION = \"v3\"\n",
    "token = \"\"\n",
    "gla = db.gla\n",
    "\n",
    "def youtube_search(options):\n",
    "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION,\n",
    "    developerKey=DEVELOPER_KEY)\n",
    "\n",
    "  # Call the search.list method to retrieve results matching the specified\n",
    "  # query term.\n",
    "    search_response = youtube.search().list(\n",
    "     q=options['q'],\n",
    "    part='id,snippet',\n",
    "    type='video',\n",
    "    location=options['location'],\n",
    "    locationRadius=options['location_radius'],\n",
    "    maxResults=options['max_results'],\n",
    "    pageToken = options['token']\n",
    "  ).execute()\n",
    "\n",
    "    search_videos = []\n",
    "\n",
    "  # Merge video ids\n",
    "    for search_result in search_response.get(\"items\", []):\n",
    "        search_videos.append(search_result[\"id\"][\"videoId\"])\n",
    "    video_ids = \",\".join(search_videos)\n",
    "\n",
    "  # Call the videos.list method to retrieve location details for each video.\n",
    "    video_response = youtube.videos().list(id=video_ids,part='snippet, recordingDetails').execute()\n",
    "    videos = []\n",
    "    total = []\n",
    "\n",
    "  # Add each result to the list, and then display the list of matching videos.\n",
    "    for video_result in video_response.get(\"items\", []):\n",
    "        videos.append(\"%s, (%s,%s)\" % (video_result[\"snippet\"][\"title\"],\n",
    "                                       video_result[\"recordingDetails\"][\"location\"][\"latitude\"],\n",
    "                                       video_result[\"recordingDetails\"][\"location\"][\"longitude\"]))\n",
    "        gla.insert_one(video_result)\n",
    "        token = search_response.get(\"nextPageToken\")\n",
    "        return token\n",
    "#     print(\"Videos:\\n\", \"\\n\".join(videos),  \"\\n\", len(videos),  \"\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    while token !=None:\n",
    "        try:    \n",
    "            args = {'q': '', \n",
    "            'location':'-4.458504, 55.742975',\n",
    "            'location_radius':'500km',\n",
    "            'max_results': 50,\n",
    "            'token':token}\n",
    "            token = youtube_search(args)\n",
    "                \n",
    "        except HttpError as e:\n",
    "             print (\"An HTTP error %d occurred:\\n%s\" % (e.resp.status, e.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. topic based data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set DEVELOPER_KEY to the API key value from the APIs & auth > Registered apps\n",
    "# tab of\n",
    "#   https://cloud.google.com/console\n",
    "# Please ensure that you have enabled the YouTube Data API for your project.\n",
    "DEVELOPER_KEY = \"AIzaSyAS66bGuv6yYysm_Rh5im6iZ2jjeuPAbpg\"\n",
    "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
    "YOUTUBE_API_VERSION = \"v3\"\n",
    "topic = db.topic\n",
    "token = \"\"\n",
    "\n",
    "def youtube_search(options):\n",
    "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION,\n",
    "    developerKey=DEVELOPER_KEY)\n",
    "\n",
    "  # Call the search.list method to retrieve results matching the specified\n",
    "  # query term.\n",
    "    search_response = youtube.search().list(\n",
    "    q=options['q'],\n",
    "    part='id,snippet',\n",
    "    maxResults=options['max_results'],\n",
    "    pageToken = options['token']\n",
    "  ).execute()\n",
    "\n",
    "    videos = []\n",
    "    channels = []\n",
    "    playlists = []\n",
    "\n",
    "  # Add each result to the appropriate list, and then display the lists of\n",
    "  # matching videos, channels, and playlists.\n",
    "    for search_result in search_response.get(\"items\", []):\n",
    "        if search_result[\"id\"][\"kind\"] == \"youtube#video\":\n",
    "            videos.append(\"%s (%s)\" % (search_result[\"snippet\"][\"title\"],\n",
    "                                 search_result[\"id\"][\"videoId\"]))\n",
    "        elif search_result[\"id\"][\"kind\"] == \"youtube#channel\":\n",
    "            channels.append(\"%s (%s)\" % (search_result[\"snippet\"][\"title\"],search_result[\"id\"][\"channelId\"]))\n",
    "        elif search_result[\"id\"][\"kind\"] == \"youtube#playlist\":\n",
    "            playlists.append(\"%s (%s)\" % (search_result[\"snippet\"][\"title\"],search_result[\"id\"][\"playlistId\"]))\n",
    "            \n",
    "        topic.insert_one(search_result)\n",
    "#     print (\"Videos:\\n\", \"\\n\".join(videos), \"\\n\", len(videos),  \"\\n\")\n",
    "#     print (\"Channels:\\n\", \"\\n\".join(channels), \"\\n\", len(channels),  \"\\n\")\n",
    "#     print (\"Playlists:\\n\", \"\\n\".join(playlists), \"\\n\", len(playlists),  \"\\n\")\n",
    "    token = search_response.get(\"nextPageToken\")  \n",
    "    return token\n",
    "keywords = np.array(['Brexit', 'Brexiter', 'EU UK talk', 'Scotlond', 'regrexit', 'Bremain'])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "     while token !=None:\n",
    "        for i in range (keywords.shape[0]):\n",
    "            try:    \n",
    "                args = {'q': keywords[i], 'max_results': 50,'token':token}\n",
    "                token = youtube_search(args)\n",
    "            except HttpError as e:\n",
    "                print (\"An HTTP error %d occurred:\\n%s\"  % (e.resp.status, e.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. count redundant topic-based data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "overlap_topic = 0\n",
    "topic = db.topic\n",
    "items = topic.aggregate([{\"$group\":{\"_id\": \"$videoId\"}}])\n",
    "for item in items:\n",
    "    id = item['_id']\n",
    "    topic_data = topic.find({\"videoId\":id})\n",
    "    \n",
    "    num = 0\n",
    "    for topicTweet in topic_data:\n",
    "        num += 1\n",
    "        if num > 1:\n",
    "            overlap_topic += num\n",
    "        else:\n",
    "            break;\n",
    "\n",
    "print(overlap_topic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. count redundant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "overlap = 0\n",
    "total = db.total\n",
    "items = total.aggregate([{\"$group\":{\"_id\": \"$videoId\"}}])\n",
    "for item in items:\n",
    "    id = item['_id']\n",
    "    total_data = total.find({\"videoId\":id})\n",
    "    \n",
    "    num = 0\n",
    "    for totalTweet in total_data:\n",
    "        num += 1\n",
    "        if num > 1:\n",
    "            overlap += num\n",
    "        else:\n",
    "            break;\n",
    "\n",
    "print(overlap)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
